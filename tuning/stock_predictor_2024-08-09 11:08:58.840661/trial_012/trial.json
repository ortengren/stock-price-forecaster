{"trial_id": "012", "hyperparameters": {"space": [{"class_name": "Choice", "config": {"name": "activation", "default": "linear", "conditions": [], "values": ["linear", "tanh"], "ordered": false}}, {"class_name": "Choice", "config": {"name": "kernel_initializer_0", "default": "glorot_uniform", "conditions": [], "values": ["glorot_uniform", "glorot_normal", "he_uniform", "he_normal", "orthogonal"], "ordered": false}}, {"class_name": "Float", "config": {"name": "dropout_0", "default": 0.2, "conditions": [], "min_value": 0.2, "max_value": 0.6, "step": null, "sampling": "linear"}}, {"class_name": "Float", "config": {"name": "recurrent_dropout_0", "default": 0.0, "conditions": [], "min_value": 0.0, "max_value": 0.25, "step": null, "sampling": "linear"}}, {"class_name": "Float", "config": {"name": "dropout_1", "default": 0.2, "conditions": [], "min_value": 0.2, "max_value": 0.6, "step": null, "sampling": "linear"}}, {"class_name": "Float", "config": {"name": "recurrent_dropout_1", "default": 0.0, "conditions": [], "min_value": 0.0, "max_value": 0.25, "step": null, "sampling": "linear"}}, {"class_name": "Choice", "config": {"name": "kernel_initializer_1", "default": "glorot_uniform", "conditions": [], "values": ["glorot_uniform", "glorot_normal", "he_uniform", "he_normal", "orthogonal"], "ordered": false}}, {"class_name": "Float", "config": {"name": "lr", "default": 5e-05, "conditions": [], "min_value": 5e-05, "max_value": 0.001, "step": null, "sampling": "linear"}}], "values": {"activation": "tanh", "kernel_initializer_0": "he_normal", "dropout_0": 0.2333615060155951, "recurrent_dropout_0": 0.1272759045495187, "dropout_1": 0.22862271507637494, "recurrent_dropout_1": 0.23044009970765408, "kernel_initializer_1": "orthogonal", "lr": 0.0009640817143162353}}, "metrics": {"metrics": {}}, "score": null, "best_step": 0, "status": "FAILED", "message": "Traceback (most recent call last):\n  File \"/home/lucas/mambaforge/envs/ece539/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/lucas/mambaforge/envs/ece539/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lucas/mambaforge/envs/ece539/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lucas/mambaforge/envs/ece539/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lucas/mambaforge/envs/ece539/lib/python3.11/site-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/lucas/mambaforge/envs/ece539/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/lucas/mambaforge/envs/ece539/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 124, in error_handler\n    del filtered_tb\nTypeError: Exception encountered when calling LSTM.call().\n\n\u001b[1mExpected int32, but got None of type 'NoneType'.\u001b[0m\n\nArguments received by LSTM.call():\n  \u2022 sequences=tf.Tensor(shape=(None, None, 32), dtype=float32)\n  \u2022 initial_state=None\n  \u2022 mask=None\n  \u2022 training=True\n"}