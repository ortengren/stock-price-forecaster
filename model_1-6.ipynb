{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa5c50a7-13cd-4c5c-b409-3c0d14086939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras_tuner\n",
    "import pmdarima as pm\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from keras import layers, ops\n",
    "from keras.utils import timeseries_dataset_from_array\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PowerTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "%matplotlib inline\n",
    "\n",
    "from processing import Stationarizer, Normalizer\n",
    "from plotting import visualize_loss, show_plot\n",
    "from model_builder import build_model, build_spec_model, get_tuner, get_64_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0401fa90-a09a-4bd2-9c62-46475a9fc2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/YF_IBM.csv\")[\"Adj Close\"]\n",
    "diff = data.dropna().to_numpy().reshape((-1, 1)) #data.diff().dropna().to_numpy().reshape((-1, 1))\n",
    "\n",
    "train_idx = int(0.7 * np.shape(diff)[0])\n",
    "val_idx = int(0.85 * np.shape(diff)[0])\n",
    "\n",
    "train_data = diff[:train_idx]\n",
    "val_data = diff[train_idx:val_idx]\n",
    "non_test_data = diff[:val_idx]\n",
    "test_data = diff[val_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61f63402-bfe6-4f41-9b0e-133093c6f364",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(non_test_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "val_data = scaler.transform(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ce210a6-21da-4093-a3cf-c49a5cbb9833",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = timeseries_dataset_from_array(\n",
    "    train_data[:-20],\n",
    "    train_data[20:],\n",
    "    sequence_length=20,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")\n",
    "val_ds = timeseries_dataset_from_array(\n",
    "    val_data[:-20],\n",
    "    val_data[20:],\n",
    "    sequence_length=20,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb59c061-f551-4204-adb8-7831b52f5282",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()    \n",
    "model.add(keras.Input(\n",
    "      shape=(20, 1),\n",
    "      batch_size=64,\n",
    "      name=\"Inputs\"\n",
    "))\n",
    "model.add(\n",
    "    layers.LSTM(\n",
    "        units=64,\n",
    "        activation=\"tanh\",\n",
    "        recurrent_activation=\"sigmoid\",\n",
    "        dropout=0.,\n",
    "        recurrent_dropout=0.,\n",
    "        return_sequences=True\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    layers.LSTM(\n",
    "        units=64,\n",
    "        activation=\"tanh\",\n",
    "        recurrent_activation=\"sigmoid\",\n",
    "        dropout=0.,\n",
    "        recurrent_dropout=0.,\n",
    "        return_sequences=False\n",
    "    )\n",
    ")\n",
    "model.add(\n",
    "    layers.Dense(\n",
    "        1,\n",
    "        activation=\"linear\"\n",
    "    )\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mse\"],\n",
    ")\n",
    "\n",
    "chkpt_path = \"checkpoints/model_2-1-2/model_checkpoint.weights.keras\"\n",
    "chkpt_cb = keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=chkpt_path,\n",
    "    verbose=1,\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "es_cb = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c21fcfd-cec5-4c7c-9cbb-0a04248a9243",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1693 - mse: 0.1693\n",
      "Epoch 1: val_loss improved from inf to 0.02343, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 0.1676 - mse: 0.1676 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 2/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0169 - mse: 0.0169\n",
      "Epoch 2: val_loss improved from 0.02343 to 0.02270, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 3/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 3: val_loss improved from 0.02270 to 0.02251, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 4/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0101 - mse: 0.0101\n",
      "Epoch 4: val_loss improved from 0.02251 to 0.02233, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 5/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 5: val_loss improved from 0.02233 to 0.02216, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0222 - val_mse: 0.0222\n",
      "Epoch 6/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0099 - mse: 0.0099\n",
      "Epoch 6: val_loss improved from 0.02216 to 0.02200, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 7/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0098 - mse: 0.0098\n",
      "Epoch 7: val_loss improved from 0.02200 to 0.02184, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 8/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0097 - mse: 0.0097\n",
      "Epoch 8: val_loss improved from 0.02184 to 0.02169, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 9/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 9: val_loss improved from 0.02169 to 0.02155, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 10/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 10: val_loss improved from 0.02155 to 0.02141, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0214 - val_mse: 0.0214\n",
      "Epoch 11/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 11: val_loss improved from 0.02141 to 0.02128, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 12/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0094 - mse: 0.0094\n",
      "Epoch 12: val_loss improved from 0.02128 to 0.02115, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 13/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 13: val_loss improved from 0.02115 to 0.02102, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0210 - val_mse: 0.0210\n",
      "Epoch 14/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0092 - mse: 0.0092\n",
      "Epoch 14: val_loss improved from 0.02102 to 0.02090, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 15/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 15: val_loss improved from 0.02090 to 0.02078, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0208 - val_mse: 0.0208\n",
      "Epoch 16/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 16: val_loss improved from 0.02078 to 0.02066, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 17/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 17: val_loss improved from 0.02066 to 0.02055, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 18/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 18: val_loss improved from 0.02055 to 0.02044, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 19/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 19: val_loss improved from 0.02044 to 0.02033, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 20/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 20: val_loss improved from 0.02033 to 0.02022, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 21/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 21: val_loss improved from 0.02022 to 0.02011, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 22/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0087 - mse: 0.0087\n",
      "Epoch 22: val_loss improved from 0.02011 to 0.02001, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 23/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0086 - mse: 0.0086\n",
      "Epoch 23: val_loss improved from 0.02001 to 0.01991, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 24/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 24: val_loss improved from 0.01991 to 0.01981, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0198 - val_mse: 0.0198\n",
      "Epoch 25/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0085 - mse: 0.0085\n",
      "Epoch 25: val_loss improved from 0.01981 to 0.01971, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0197 - val_mse: 0.0197\n",
      "Epoch 26/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 26: val_loss improved from 0.01971 to 0.01962, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0196 - val_mse: 0.0196\n",
      "Epoch 27/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 27: val_loss improved from 0.01962 to 0.01952, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 28/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 28: val_loss improved from 0.01952 to 0.01943, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 29/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 29: val_loss improved from 0.01943 to 0.01934, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0193 - val_mse: 0.0193\n",
      "Epoch 30/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 30: val_loss improved from 0.01934 to 0.01925, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 31/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0082 - mse: 0.0082\n",
      "Epoch 31: val_loss improved from 0.01925 to 0.01916, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0192 - val_mse: 0.0192\n",
      "Epoch 32/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 32: val_loss improved from 0.01916 to 0.01907, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0191 - val_mse: 0.0191\n",
      "Epoch 33/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 33: val_loss improved from 0.01907 to 0.01898, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0190 - val_mse: 0.0190\n",
      "Epoch 34/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 34: val_loss improved from 0.01898 to 0.01890, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0189 - val_mse: 0.0189\n",
      "Epoch 35/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 35: val_loss improved from 0.01890 to 0.01881, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 36/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 36: val_loss improved from 0.01881 to 0.01873, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 37/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 37: val_loss improved from 0.01873 to 0.01865, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 38/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 38: val_loss improved from 0.01865 to 0.01857, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 39/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 39: val_loss improved from 0.01857 to 0.01849, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 40/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 40: val_loss improved from 0.01849 to 0.01841, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0184 - val_mse: 0.0184\n",
      "Epoch 41/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0078 - mse: 0.0078\n",
      "Epoch 41: val_loss improved from 0.01841 to 0.01833, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 42/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 42: val_loss improved from 0.01833 to 0.01825, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 43/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 43: val_loss improved from 0.01825 to 0.01818, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 44/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0077 - mse: 0.0077\n",
      "Epoch 44: val_loss improved from 0.01818 to 0.01810, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 45/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 45: val_loss improved from 0.01810 to 0.01803, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 46/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 46: val_loss improved from 0.01803 to 0.01796, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 47/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0076 - mse: 0.0076\n",
      "Epoch 47: val_loss improved from 0.01796 to 0.01788, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 48/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 48: val_loss improved from 0.01788 to 0.01781, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0178 - val_mse: 0.0178\n",
      "Epoch 49/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 49: val_loss improved from 0.01781 to 0.01774, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 50/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 50: val_loss improved from 0.01774 to 0.01767, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 51/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 51: val_loss improved from 0.01767 to 0.01760, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0176 - val_mse: 0.0176\n",
      "Epoch 52/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 52: val_loss improved from 0.01760 to 0.01753, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 53/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 53: val_loss improved from 0.01753 to 0.01746, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0175 - val_mse: 0.0175\n",
      "Epoch 54/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 54: val_loss improved from 0.01746 to 0.01739, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0174 - val_mse: 0.0174\n",
      "Epoch 55/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 55: val_loss improved from 0.01739 to 0.01733, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 56/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0073 - mse: 0.0073\n",
      "Epoch 56: val_loss improved from 0.01733 to 0.01726, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 57/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 57: val_loss improved from 0.01726 to 0.01720, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 58/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 58: val_loss improved from 0.01720 to 0.01713, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 59/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 59: val_loss improved from 0.01713 to 0.01707, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 60/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 60: val_loss improved from 0.01707 to 0.01700, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 61/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 61: val_loss improved from 0.01700 to 0.01694, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 62/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 62: val_loss improved from 0.01694 to 0.01688, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 63/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 63: val_loss improved from 0.01688 to 0.01681, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 64/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 64: val_loss improved from 0.01681 to 0.01675, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 65/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 65: val_loss improved from 0.01675 to 0.01669, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 66/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 66: val_loss improved from 0.01669 to 0.01663, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 67/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0070 - mse: 0.0070\n",
      "Epoch 67: val_loss improved from 0.01663 to 0.01657, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0166 - val_mse: 0.0166\n",
      "Epoch 68/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 68: val_loss improved from 0.01657 to 0.01651, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 69/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 69: val_loss improved from 0.01651 to 0.01645, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 70/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 70: val_loss improved from 0.01645 to 0.01640, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 71/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0069 - mse: 0.0069\n",
      "Epoch 71: val_loss improved from 0.01640 to 0.01634, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 72/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 72: val_loss improved from 0.01634 to 0.01628, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 73/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 73: val_loss improved from 0.01628 to 0.01622, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 74/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 74: val_loss improved from 0.01622 to 0.01617, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 75/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 75: val_loss improved from 0.01617 to 0.01611, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 76/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 76: val_loss improved from 0.01611 to 0.01606, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 77/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 77: val_loss improved from 0.01606 to 0.01600, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 78/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 78: val_loss improved from 0.01600 to 0.01595, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 79/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 79: val_loss improved from 0.01595 to 0.01589, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 80/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 80: val_loss improved from 0.01589 to 0.01584, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 81/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 81: val_loss improved from 0.01584 to 0.01578, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0158 - val_mse: 0.0158\n",
      "Epoch 82/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 82: val_loss improved from 0.01578 to 0.01573, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 83/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 83: val_loss improved from 0.01573 to 0.01568, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0157 - val_mse: 0.0157\n",
      "Epoch 84/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0066 - mse: 0.0066\n",
      "Epoch 84: val_loss improved from 0.01568 to 0.01563, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 85/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 85: val_loss improved from 0.01563 to 0.01557, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 86/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 86: val_loss improved from 0.01557 to 0.01552, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 87/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 87: val_loss improved from 0.01552 to 0.01547, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 88/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0065 - mse: 0.0065\n",
      "Epoch 88: val_loss improved from 0.01547 to 0.01542, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 89/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 89: val_loss improved from 0.01542 to 0.01537, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0154 - val_mse: 0.0154\n",
      "Epoch 90/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 90: val_loss improved from 0.01537 to 0.01532, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 91/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 91: val_loss improved from 0.01532 to 0.01527, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0153 - val_mse: 0.0153\n",
      "Epoch 92/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 92: val_loss improved from 0.01527 to 0.01522, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 93/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 93: val_loss improved from 0.01522 to 0.01517, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0152 - val_mse: 0.0152\n",
      "Epoch 94/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 94: val_loss improved from 0.01517 to 0.01513, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 95/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 95: val_loss improved from 0.01513 to 0.01508, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0151 - val_mse: 0.0151\n",
      "Epoch 96/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 96: val_loss improved from 0.01508 to 0.01503, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 97/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 97: val_loss improved from 0.01503 to 0.01498, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 98/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 98: val_loss improved from 0.01498 to 0.01493, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 99/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 99: val_loss improved from 0.01493 to 0.01489, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 100/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 100: val_loss improved from 0.01489 to 0.01484, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 101/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 101: val_loss improved from 0.01484 to 0.01479, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0148 - val_mse: 0.0148\n",
      "Epoch 102/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 102: val_loss improved from 0.01479 to 0.01475, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 103/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 103: val_loss improved from 0.01475 to 0.01470, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0062 - mse: 0.0062 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 104/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 104: val_loss improved from 0.01470 to 0.01466, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 105/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 105: val_loss improved from 0.01466 to 0.01461, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 106/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 106: val_loss improved from 0.01461 to 0.01457, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 107/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 107: val_loss improved from 0.01457 to 0.01452, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 108/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 108: val_loss improved from 0.01452 to 0.01448, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 109/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 109: val_loss improved from 0.01448 to 0.01444, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 110/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 110: val_loss improved from 0.01444 to 0.01439, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 111/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 111: val_loss improved from 0.01439 to 0.01435, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 112/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 112: val_loss improved from 0.01435 to 0.01431, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 113/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 113: val_loss improved from 0.01431 to 0.01426, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 114/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 114: val_loss improved from 0.01426 to 0.01422, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 115/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0060 - mse: 0.0060\n",
      "Epoch 115: val_loss improved from 0.01422 to 0.01418, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 116/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 116: val_loss improved from 0.01418 to 0.01414, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 117/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 117: val_loss improved from 0.01414 to 0.01409, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 118/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 118: val_loss improved from 0.01409 to 0.01405, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 119/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 119: val_loss improved from 0.01405 to 0.01401, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 120/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 120: val_loss improved from 0.01401 to 0.01397, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 121/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0059 - mse: 0.0059\n",
      "Epoch 121: val_loss improved from 0.01397 to 0.01393, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0059 - mse: 0.0059 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 122/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 122: val_loss improved from 0.01393 to 0.01389, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 123/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 123: val_loss improved from 0.01389 to 0.01385, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 124/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 124: val_loss improved from 0.01385 to 0.01381, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 125/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 125: val_loss improved from 0.01381 to 0.01377, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 126/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 126: val_loss improved from 0.01377 to 0.01373, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 127/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 127: val_loss improved from 0.01373 to 0.01369, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 128/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0058 - mse: 0.0058\n",
      "Epoch 128: val_loss improved from 0.01369 to 0.01365, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 129/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 129: val_loss improved from 0.01365 to 0.01361, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 130/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 130: val_loss improved from 0.01361 to 0.01358, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0136 - val_mse: 0.0136\n",
      "Epoch 131/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 131: val_loss improved from 0.01358 to 0.01354, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 132/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 132: val_loss improved from 0.01354 to 0.01350, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 133/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 133: val_loss improved from 0.01350 to 0.01346, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 134/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 134: val_loss improved from 0.01346 to 0.01342, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 135/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 135: val_loss improved from 0.01342 to 0.01339, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0134 - val_mse: 0.0134\n",
      "Epoch 136/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 136: val_loss improved from 0.01339 to 0.01335, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 137/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 137: val_loss improved from 0.01335 to 0.01331, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 138/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 138: val_loss improved from 0.01331 to 0.01328, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0133 - val_mse: 0.0133\n",
      "Epoch 139/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 139: val_loss improved from 0.01328 to 0.01324, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 140/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 140: val_loss improved from 0.01324 to 0.01320, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 141/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 141: val_loss improved from 0.01320 to 0.01317, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 142/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 142: val_loss improved from 0.01317 to 0.01313, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 143/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 143: val_loss improved from 0.01313 to 0.01310, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 144/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 144: val_loss improved from 0.01310 to 0.01306, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 145/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 145: val_loss improved from 0.01306 to 0.01303, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 146/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 146: val_loss improved from 0.01303 to 0.01299, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 147/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 147: val_loss improved from 0.01299 to 0.01296, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 148/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 148: val_loss improved from 0.01296 to 0.01292, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 149/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 149: val_loss improved from 0.01292 to 0.01289, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 150/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 150: val_loss improved from 0.01289 to 0.01285, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0129 - val_mse: 0.0129\n",
      "Epoch 151/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 151: val_loss improved from 0.01285 to 0.01282, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 152/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 152: val_loss improved from 0.01282 to 0.01279, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 153/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 153: val_loss improved from 0.01279 to 0.01275, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 154/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 154: val_loss improved from 0.01275 to 0.01272, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 155/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 155: val_loss improved from 0.01272 to 0.01269, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 156/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 156: val_loss improved from 0.01269 to 0.01265, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0127 - val_mse: 0.0127\n",
      "Epoch 157/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 157: val_loss improved from 0.01265 to 0.01262, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 158/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 158: val_loss improved from 0.01262 to 0.01259, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 159/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 159: val_loss improved from 0.01259 to 0.01256, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 160/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 160: val_loss improved from 0.01256 to 0.01252, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 161/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 161: val_loss improved from 0.01252 to 0.01249, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 162/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 162: val_loss improved from 0.01249 to 0.01246, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 163/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 163: val_loss improved from 0.01246 to 0.01243, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 164/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 164: val_loss improved from 0.01243 to 0.01240, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 165/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 165: val_loss improved from 0.01240 to 0.01237, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 166/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 166: val_loss improved from 0.01237 to 0.01234, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 167/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 167: val_loss improved from 0.01234 to 0.01231, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 168/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 168: val_loss improved from 0.01231 to 0.01228, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 169/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 169: val_loss improved from 0.01228 to 0.01224, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 170/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 170: val_loss improved from 0.01224 to 0.01221, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 171/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 171: val_loss improved from 0.01221 to 0.01218, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 172/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 172: val_loss improved from 0.01218 to 0.01216, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 173/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 173: val_loss improved from 0.01216 to 0.01213, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 174/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 174: val_loss improved from 0.01213 to 0.01210, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 175/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 175: val_loss improved from 0.01210 to 0.01207, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 176/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 176: val_loss improved from 0.01207 to 0.01204, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 177/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 177: val_loss improved from 0.01204 to 0.01201, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 178/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 178: val_loss improved from 0.01201 to 0.01198, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 179/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 179: val_loss improved from 0.01198 to 0.01195, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 180/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 180: val_loss improved from 0.01195 to 0.01192, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 181/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 181: val_loss improved from 0.01192 to 0.01190, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 182/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0051 - mse: 0.0051\n",
      "Epoch 182: val_loss improved from 0.01190 to 0.01187, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 183/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 183: val_loss improved from 0.01187 to 0.01184, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 184/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 184: val_loss improved from 0.01184 to 0.01181, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 185/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 185: val_loss improved from 0.01181 to 0.01179, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 186/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 186: val_loss improved from 0.01179 to 0.01176, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 187/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 187: val_loss improved from 0.01176 to 0.01173, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 188/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 188: val_loss improved from 0.01173 to 0.01170, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 189/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 189: val_loss improved from 0.01170 to 0.01168, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 190/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 190: val_loss improved from 0.01168 to 0.01165, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 191/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 191: val_loss improved from 0.01165 to 0.01163, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 192/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0050 - mse: 0.0050\n",
      "Epoch 192: val_loss improved from 0.01163 to 0.01160, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 193/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 193: val_loss improved from 0.01160 to 0.01157, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 194/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 194: val_loss improved from 0.01157 to 0.01155, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 195/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 195: val_loss improved from 0.01155 to 0.01152, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 196/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 196: val_loss improved from 0.01152 to 0.01150, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 197/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 197: val_loss improved from 0.01150 to 0.01147, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 198/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 198: val_loss improved from 0.01147 to 0.01145, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 199/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 199: val_loss improved from 0.01145 to 0.01142, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 200/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 200: val_loss improved from 0.01142 to 0.01140, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 201/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 201: val_loss improved from 0.01140 to 0.01137, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 202/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 202: val_loss improved from 0.01137 to 0.01135, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 203/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0049 - mse: 0.0049\n",
      "Epoch 203: val_loss improved from 0.01135 to 0.01132, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 204/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 204: val_loss improved from 0.01132 to 0.01130, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 205/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 205: val_loss improved from 0.01130 to 0.01128, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 206/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 206: val_loss improved from 0.01128 to 0.01125, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 207/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 207: val_loss improved from 0.01125 to 0.01123, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 208/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 208: val_loss improved from 0.01123 to 0.01121, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 209/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 209: val_loss improved from 0.01121 to 0.01118, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 210/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 210: val_loss improved from 0.01118 to 0.01116, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 211/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 211: val_loss improved from 0.01116 to 0.01114, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 212/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 212: val_loss improved from 0.01114 to 0.01111, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 213/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 213: val_loss improved from 0.01111 to 0.01109, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 214/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 214: val_loss improved from 0.01109 to 0.01107, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 215/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 215: val_loss improved from 0.01107 to 0.01105, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 216/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 216: val_loss improved from 0.01105 to 0.01102, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 217/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 217: val_loss improved from 0.01102 to 0.01100, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 218/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 218: val_loss improved from 0.01100 to 0.01098, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 219/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 219: val_loss improved from 0.01098 to 0.01096, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 220/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 220: val_loss improved from 0.01096 to 0.01094, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 221/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 221: val_loss improved from 0.01094 to 0.01092, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 222/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 222: val_loss improved from 0.01092 to 0.01089, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 223/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 223: val_loss improved from 0.01089 to 0.01087, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 224/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 224: val_loss improved from 0.01087 to 0.01085, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 225/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 225: val_loss improved from 0.01085 to 0.01083, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 226/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 226: val_loss improved from 0.01083 to 0.01081, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 227/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 227: val_loss improved from 0.01081 to 0.01079, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 228/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 228: val_loss improved from 0.01079 to 0.01077, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 229/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 229: val_loss improved from 0.01077 to 0.01075, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 230/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 230: val_loss improved from 0.01075 to 0.01073, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 231/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 231: val_loss improved from 0.01073 to 0.01071, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 232/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 232: val_loss improved from 0.01071 to 0.01069, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 233/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 233: val_loss improved from 0.01069 to 0.01067, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 234/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 234: val_loss improved from 0.01067 to 0.01065, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 235/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 235: val_loss improved from 0.01065 to 0.01063, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 236/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 236: val_loss improved from 0.01063 to 0.01061, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 237/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 237: val_loss improved from 0.01061 to 0.01059, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 238/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 238: val_loss improved from 0.01059 to 0.01058, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 239/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 239: val_loss improved from 0.01058 to 0.01056, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 240/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 240: val_loss improved from 0.01056 to 0.01054, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 241/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 241: val_loss improved from 0.01054 to 0.01052, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 242/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 242: val_loss improved from 0.01052 to 0.01050, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 243/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 243: val_loss improved from 0.01050 to 0.01048, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 244/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 244: val_loss improved from 0.01048 to 0.01047, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 245/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 245: val_loss improved from 0.01047 to 0.01045, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 246/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 246: val_loss improved from 0.01045 to 0.01043, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 247/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 247: val_loss improved from 0.01043 to 0.01041, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 248/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 248: val_loss improved from 0.01041 to 0.01039, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 249/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 249: val_loss improved from 0.01039 to 0.01038, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 250/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 250: val_loss improved from 0.01038 to 0.01036, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 251/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 251: val_loss improved from 0.01036 to 0.01034, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 252/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 252: val_loss improved from 0.01034 to 0.01033, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 253/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 253: val_loss improved from 0.01033 to 0.01031, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 254/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 254: val_loss improved from 0.01031 to 0.01029, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 255/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 255: val_loss improved from 0.01029 to 0.01028, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 256/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 256: val_loss improved from 0.01028 to 0.01026, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 257/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 257: val_loss improved from 0.01026 to 0.01024, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 258/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 258: val_loss improved from 0.01024 to 0.01023, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 259/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 259: val_loss improved from 0.01023 to 0.01021, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 260/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 260: val_loss improved from 0.01021 to 0.01020, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 261/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 261: val_loss improved from 0.01020 to 0.01018, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 262/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 262: val_loss improved from 0.01018 to 0.01016, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 263/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 263: val_loss improved from 0.01016 to 0.01015, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 264/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 264: val_loss improved from 0.01015 to 0.01013, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 265/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 265: val_loss improved from 0.01013 to 0.01012, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 266/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 266: val_loss improved from 0.01012 to 0.01010, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 267/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 267: val_loss improved from 0.01010 to 0.01009, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 268/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 268: val_loss improved from 0.01009 to 0.01007, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 269/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 269: val_loss improved from 0.01007 to 0.01006, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0101 - val_mse: 0.0101\n",
      "Epoch 270/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 270: val_loss improved from 0.01006 to 0.01004, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 271/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 271: val_loss improved from 0.01004 to 0.01003, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 272/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 272: val_loss improved from 0.01003 to 0.01001, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 273/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 273: val_loss improved from 0.01001 to 0.01000, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 274/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 274: val_loss improved from 0.01000 to 0.00998, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 275/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 275: val_loss improved from 0.00998 to 0.00997, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 276/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 276: val_loss improved from 0.00997 to 0.00996, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0100 - val_mse: 0.0100\n",
      "Epoch 277/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 277: val_loss improved from 0.00996 to 0.00994, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 278/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 278: val_loss improved from 0.00994 to 0.00993, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 279/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 279: val_loss improved from 0.00993 to 0.00991, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 280/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 280: val_loss improved from 0.00991 to 0.00990, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 281/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 281: val_loss improved from 0.00990 to 0.00989, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 282/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 282: val_loss improved from 0.00989 to 0.00987, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 283/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 283: val_loss improved from 0.00987 to 0.00986, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 284/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 284: val_loss improved from 0.00986 to 0.00985, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 285/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 285: val_loss improved from 0.00985 to 0.00983, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 286/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 286: val_loss improved from 0.00983 to 0.00982, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 287/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 287: val_loss improved from 0.00982 to 0.00981, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 288/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 288: val_loss improved from 0.00981 to 0.00979, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 289/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 289: val_loss improved from 0.00979 to 0.00978, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 290/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 290: val_loss improved from 0.00978 to 0.00977, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 291/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 291: val_loss improved from 0.00977 to 0.00976, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 292/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 292: val_loss improved from 0.00976 to 0.00974, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 293/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 293: val_loss improved from 0.00974 to 0.00973, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 294/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 294: val_loss improved from 0.00973 to 0.00972, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 295/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 295: val_loss improved from 0.00972 to 0.00971, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 296/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 296: val_loss improved from 0.00971 to 0.00969, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 297/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 297: val_loss improved from 0.00969 to 0.00968, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 298/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 298: val_loss improved from 0.00968 to 0.00967, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 299/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 299: val_loss improved from 0.00967 to 0.00966, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 300/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 300: val_loss improved from 0.00966 to 0.00965, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 301/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 301: val_loss improved from 0.00965 to 0.00964, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 302/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 302: val_loss improved from 0.00964 to 0.00962, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 303/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 303: val_loss improved from 0.00962 to 0.00961, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 304/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 304: val_loss improved from 0.00961 to 0.00960, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 305/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 305: val_loss improved from 0.00960 to 0.00959, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 306/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 306: val_loss improved from 0.00959 to 0.00958, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 307/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 307: val_loss improved from 0.00958 to 0.00957, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 308/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 308: val_loss improved from 0.00957 to 0.00956, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 309/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 309: val_loss improved from 0.00956 to 0.00954, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 310/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 310: val_loss improved from 0.00954 to 0.00953, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 311/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 311: val_loss improved from 0.00953 to 0.00952, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 312/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 312: val_loss improved from 0.00952 to 0.00951, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 313/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 313: val_loss improved from 0.00951 to 0.00950, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 314/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 314: val_loss improved from 0.00950 to 0.00949, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 315/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 315: val_loss improved from 0.00949 to 0.00948, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 316/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 316: val_loss improved from 0.00948 to 0.00947, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 317/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 317: val_loss improved from 0.00947 to 0.00946, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 318/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 318: val_loss improved from 0.00946 to 0.00945, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 319/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 319: val_loss improved from 0.00945 to 0.00944, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 320/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 320: val_loss improved from 0.00944 to 0.00943, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 321/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 321: val_loss improved from 0.00943 to 0.00942, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 322/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 322: val_loss improved from 0.00942 to 0.00941, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 323/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 323: val_loss improved from 0.00941 to 0.00940, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 324/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 324: val_loss improved from 0.00940 to 0.00939, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 325/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 325: val_loss improved from 0.00939 to 0.00938, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 326/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 326: val_loss improved from 0.00938 to 0.00937, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 327/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 327: val_loss improved from 0.00937 to 0.00936, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 328/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 328: val_loss improved from 0.00936 to 0.00935, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 329/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 329: val_loss improved from 0.00935 to 0.00934, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 330/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 330: val_loss improved from 0.00934 to 0.00933, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 331/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 331: val_loss improved from 0.00933 to 0.00932, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 332/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 332: val_loss improved from 0.00932 to 0.00931, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 333/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 333: val_loss improved from 0.00931 to 0.00930, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 334/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 334: val_loss improved from 0.00930 to 0.00929, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 335/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 335: val_loss improved from 0.00929 to 0.00928, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 336/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 336: val_loss improved from 0.00928 to 0.00927, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 337/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 337: val_loss improved from 0.00927 to 0.00926, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 338/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 338: val_loss improved from 0.00926 to 0.00925, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 339/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 339: val_loss improved from 0.00925 to 0.00925, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 340/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 340: val_loss improved from 0.00925 to 0.00924, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 341/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 341: val_loss improved from 0.00924 to 0.00923, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 342/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 342: val_loss improved from 0.00923 to 0.00922, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 343/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 343: val_loss improved from 0.00922 to 0.00921, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 344/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 344: val_loss improved from 0.00921 to 0.00920, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 345/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 345: val_loss improved from 0.00920 to 0.00919, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 346/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 346: val_loss improved from 0.00919 to 0.00918, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 347/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 347: val_loss improved from 0.00918 to 0.00918, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 348/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 348: val_loss improved from 0.00918 to 0.00917, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 349/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 349: val_loss improved from 0.00917 to 0.00916, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 350/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 350: val_loss improved from 0.00916 to 0.00915, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 351/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 351: val_loss improved from 0.00915 to 0.00914, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 352/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 352: val_loss improved from 0.00914 to 0.00913, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 353/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 353: val_loss improved from 0.00913 to 0.00912, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 354/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 354: val_loss improved from 0.00912 to 0.00912, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 355/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 355: val_loss improved from 0.00912 to 0.00911, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 356/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 356: val_loss improved from 0.00911 to 0.00910, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 357/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 357: val_loss improved from 0.00910 to 0.00909, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 358/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 358: val_loss improved from 0.00909 to 0.00908, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 359/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 359: val_loss improved from 0.00908 to 0.00908, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 360/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 360: val_loss improved from 0.00908 to 0.00907, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 361/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 361: val_loss improved from 0.00907 to 0.00906, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 362/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 362: val_loss improved from 0.00906 to 0.00905, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0091 - val_mse: 0.0091\n",
      "Epoch 363/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 363: val_loss improved from 0.00905 to 0.00904, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 364/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 364: val_loss improved from 0.00904 to 0.00904, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 365/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 365: val_loss improved from 0.00904 to 0.00903, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 366/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 366: val_loss improved from 0.00903 to 0.00902, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 367/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 367: val_loss improved from 0.00902 to 0.00901, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 368/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 368: val_loss improved from 0.00901 to 0.00901, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 369/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 369: val_loss improved from 0.00901 to 0.00900, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 370/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 370: val_loss improved from 0.00900 to 0.00899, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 371/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 371: val_loss improved from 0.00899 to 0.00898, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 372/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 372: val_loss improved from 0.00898 to 0.00898, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 373/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 373: val_loss improved from 0.00898 to 0.00897, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 374/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 374: val_loss improved from 0.00897 to 0.00896, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 375/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 375: val_loss improved from 0.00896 to 0.00895, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 376/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 376: val_loss improved from 0.00895 to 0.00895, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 377/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 377: val_loss improved from 0.00895 to 0.00894, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 378/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 378: val_loss improved from 0.00894 to 0.00893, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 379/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 379: val_loss improved from 0.00893 to 0.00892, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 380/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 380: val_loss improved from 0.00892 to 0.00892, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 381/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 381: val_loss improved from 0.00892 to 0.00891, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 382/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 382: val_loss improved from 0.00891 to 0.00890, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 383/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 383: val_loss improved from 0.00890 to 0.00890, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 384/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 384: val_loss improved from 0.00890 to 0.00889, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 385/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 385: val_loss improved from 0.00889 to 0.00888, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 386/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 386: val_loss improved from 0.00888 to 0.00887, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 387/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 387: val_loss improved from 0.00887 to 0.00887, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 388/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 388: val_loss improved from 0.00887 to 0.00886, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 389/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 389: val_loss improved from 0.00886 to 0.00885, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 390/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 390: val_loss improved from 0.00885 to 0.00885, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 391/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 391: val_loss improved from 0.00885 to 0.00884, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 392/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 392: val_loss improved from 0.00884 to 0.00883, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 393/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 393: val_loss improved from 0.00883 to 0.00883, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 394/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 394: val_loss improved from 0.00883 to 0.00882, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 395/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 395: val_loss improved from 0.00882 to 0.00881, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 396/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 396: val_loss improved from 0.00881 to 0.00881, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 397/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 397: val_loss improved from 0.00881 to 0.00880, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 398/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 398: val_loss improved from 0.00880 to 0.00879, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 399/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 399: val_loss improved from 0.00879 to 0.00879, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 400/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 400: val_loss improved from 0.00879 to 0.00878, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 401/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 401: val_loss improved from 0.00878 to 0.00877, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 402/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 402: val_loss improved from 0.00877 to 0.00877, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 403/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 403: val_loss improved from 0.00877 to 0.00876, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 404/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 404: val_loss improved from 0.00876 to 0.00875, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0088 - val_mse: 0.0088\n",
      "Epoch 405/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 405: val_loss improved from 0.00875 to 0.00875, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 406/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 406: val_loss improved from 0.00875 to 0.00874, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 407/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 407: val_loss improved from 0.00874 to 0.00874, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 408/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 408: val_loss improved from 0.00874 to 0.00873, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 409/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 409: val_loss improved from 0.00873 to 0.00872, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 410/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 410: val_loss improved from 0.00872 to 0.00872, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 411/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 411: val_loss improved from 0.00872 to 0.00871, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 412/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 412: val_loss improved from 0.00871 to 0.00870, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 413/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 413: val_loss improved from 0.00870 to 0.00870, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 414/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 414: val_loss improved from 0.00870 to 0.00869, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 415/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Epoch 415: val_loss improved from 0.00869 to 0.00869, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 416/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 416: val_loss improved from 0.00869 to 0.00868, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 417/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 417: val_loss improved from 0.00868 to 0.00867, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 418/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 418: val_loss improved from 0.00867 to 0.00867, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 419/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 419: val_loss improved from 0.00867 to 0.00866, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 420/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 420: val_loss improved from 0.00866 to 0.00866, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 421/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 421: val_loss improved from 0.00866 to 0.00865, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 422/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 422: val_loss improved from 0.00865 to 0.00864, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 423/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 423: val_loss improved from 0.00864 to 0.00864, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 424/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 424: val_loss improved from 0.00864 to 0.00863, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 425/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 425: val_loss improved from 0.00863 to 0.00863, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 426/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 426: val_loss improved from 0.00863 to 0.00862, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 427/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 427: val_loss improved from 0.00862 to 0.00861, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 428/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 428: val_loss improved from 0.00861 to 0.00861, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 429/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 429: val_loss improved from 0.00861 to 0.00860, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 430/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 430: val_loss improved from 0.00860 to 0.00860, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 431/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 431: val_loss improved from 0.00860 to 0.00859, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 432/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 432: val_loss improved from 0.00859 to 0.00859, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 433/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 433: val_loss improved from 0.00859 to 0.00858, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 434/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 434: val_loss improved from 0.00858 to 0.00857, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 435/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 435: val_loss improved from 0.00857 to 0.00857, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 436/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 436: val_loss improved from 0.00857 to 0.00856, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 437/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 437: val_loss improved from 0.00856 to 0.00856, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 438/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 438: val_loss improved from 0.00856 to 0.00855, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 439/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 439: val_loss improved from 0.00855 to 0.00855, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 440/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 440: val_loss improved from 0.00855 to 0.00854, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 441/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 441: val_loss improved from 0.00854 to 0.00853, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 442/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 442: val_loss improved from 0.00853 to 0.00853, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 443/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 443: val_loss improved from 0.00853 to 0.00852, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 444/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 444: val_loss improved from 0.00852 to 0.00852, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 445/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 445: val_loss improved from 0.00852 to 0.00851, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 446/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 446: val_loss improved from 0.00851 to 0.00851, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 447/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 447: val_loss improved from 0.00851 to 0.00850, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 448/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 448: val_loss improved from 0.00850 to 0.00850, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 449/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 449: val_loss improved from 0.00850 to 0.00849, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 450/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 450: val_loss improved from 0.00849 to 0.00849, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 451/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 451: val_loss improved from 0.00849 to 0.00848, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 452/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 452: val_loss improved from 0.00848 to 0.00847, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 453/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 453: val_loss improved from 0.00847 to 0.00847, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 454/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 454: val_loss improved from 0.00847 to 0.00846, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 455/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 455: val_loss improved from 0.00846 to 0.00846, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 456/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 456: val_loss improved from 0.00846 to 0.00845, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 457/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 457: val_loss improved from 0.00845 to 0.00845, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 458/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 458: val_loss improved from 0.00845 to 0.00844, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 459/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 459: val_loss improved from 0.00844 to 0.00844, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 460/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 460: val_loss improved from 0.00844 to 0.00843, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 461/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - mse: 0.0038\n",
      "Epoch 461: val_loss improved from 0.00843 to 0.00843, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 462/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 462: val_loss improved from 0.00843 to 0.00842, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 463/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 463: val_loss improved from 0.00842 to 0.00842, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 464/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 464: val_loss improved from 0.00842 to 0.00841, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 465/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 465: val_loss improved from 0.00841 to 0.00841, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 466/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 466: val_loss improved from 0.00841 to 0.00840, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 467/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 467: val_loss improved from 0.00840 to 0.00840, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 468/500\n",
      "\u001b[1m65/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 468: val_loss improved from 0.00840 to 0.00839, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 469/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 469: val_loss improved from 0.00839 to 0.00839, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 470/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 470: val_loss improved from 0.00839 to 0.00838, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 471/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 471: val_loss improved from 0.00838 to 0.00838, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 472/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 472: val_loss improved from 0.00838 to 0.00837, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 473/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 473: val_loss improved from 0.00837 to 0.00837, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 474/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 474: val_loss improved from 0.00837 to 0.00836, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 475/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 475: val_loss improved from 0.00836 to 0.00836, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 476/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 476: val_loss improved from 0.00836 to 0.00835, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 477/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 477: val_loss improved from 0.00835 to 0.00835, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 478/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 478: val_loss improved from 0.00835 to 0.00834, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 479/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 479: val_loss improved from 0.00834 to 0.00834, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 480/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 480: val_loss improved from 0.00834 to 0.00833, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 481/500\n",
      "\u001b[1m65/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m14s\u001b[0m 7s/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 481: val_loss improved from 0.00833 to 0.00833, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 7s/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 482/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - loss: 0.0037 - mse: 0.0037 \n",
      "Epoch 482: val_loss improved from 0.00833 to 0.00832, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m720s\u001b[0m 11s/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 483/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 483: val_loss improved from 0.00832 to 0.00832, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 484/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 484: val_loss improved from 0.00832 to 0.00831, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 485/500\n",
      "\u001b[1m65/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 485: val_loss improved from 0.00831 to 0.00831, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 486/500\n",
      "\u001b[1m65/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 486: val_loss improved from 0.00831 to 0.00830, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 487/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 487: val_loss improved from 0.00830 to 0.00830, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 488/500\n",
      "\u001b[1m66/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 488: val_loss improved from 0.00830 to 0.00829, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 489/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 489: val_loss improved from 0.00829 to 0.00829, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 490/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 490: val_loss improved from 0.00829 to 0.00828, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 491/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 491: val_loss improved from 0.00828 to 0.00828, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 492/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 492: val_loss improved from 0.00828 to 0.00827, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 493/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 493: val_loss improved from 0.00827 to 0.00827, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 494/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 494: val_loss improved from 0.00827 to 0.00826, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 495/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 495: val_loss improved from 0.00826 to 0.00826, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 496/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 496: val_loss improved from 0.00826 to 0.00825, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 497/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 497: val_loss improved from 0.00825 to 0.00825, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 498/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 498: val_loss improved from 0.00825 to 0.00824, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 499/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 499: val_loss improved from 0.00824 to 0.00824, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 500/500\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 500: val_loss improved from 0.00824 to 0.00823, saving model to checkpoints/model_2-1-2/model_checkpoint.weights.keras\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0082 - val_mse: 0.0082\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=500,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[chkpt_cb, es_cb]\n",
    ")\n",
    "\n",
    "visualize_loss(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba90b7a-6723-494b-9bb0-ab5273c8526a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "770020d0-a76a-44d5-83f8-9536594b1fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 20:45:13.339329: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(20, 1), dtype=float64, numpy=\n",
       " array([[1.53948556],\n",
       "        [1.54965541],\n",
       "        [1.60123244],\n",
       "        [1.56684676],\n",
       "        [1.55522458],\n",
       "        [1.56539416],\n",
       "        [1.56321512],\n",
       "        [1.54069692],\n",
       "        [1.48573003],\n",
       "        [1.50146851],\n",
       "        [1.46829609],\n",
       "        [1.45037695],\n",
       "        [1.45255788],\n",
       "        [1.48718237],\n",
       "        [1.44868175],\n",
       "        [1.44989338],\n",
       "        [1.40582358],\n",
       "        [1.42761534],\n",
       "        [1.42858383],\n",
       "        [1.40461331]])>,\n",
       " <tf.Tensor: shape=(1,), dtype=float64, numpy=array([1.40315908])>,\n",
       " array([1.4130204], dtype=float32)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "\n",
    "for x, y in val_ds:\n",
    "    yhat = model.predict(x)\n",
    "    for el in range(x.shape[0]):\n",
    "        preds.append([x[el], y[el], yhat[el]])\n",
    "    \n",
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc9e99cc-8d66-46dd-87de-966a7b3c506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([float(el[1]) for el in preds]).reshape((-1, 1))\n",
    "yhat = np.array([float(el[2]) for el in preds]).reshape((-1, 1))\n",
    "\n",
    "y_r = scaler.inverse_transform(y)\n",
    "yhat_r = scaler.inverse_transform(yhat)\n",
    "\n",
    "y_r = y_r.flatten()\n",
    "yhat_r = yhat_r.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a411a32-48c2-48ea-a5ba-82d20d9f25ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 150.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(y_r.shape[0]), y_r)\n",
    "plt.plot(np.arange(yhat_r.shape[0]), yhat_r)\n",
    "plt.ylim((0, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba32bf30-42e2-49a2-a540-a69e95682d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Lag', ylabel='Autocorrelation'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sta = data.diff().dropna().to_numpy().reshape((-1, 1))\n",
    "sc = StandardScaler()\n",
    "scsta = sc.fit_transform(sta)\n",
    "#plt.plot(np.arange(sta.shape[0]), sta)\n",
    "autocorrelation_plot(y_r[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5599a020-aa6e-4780-a8df-4917ea87b746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:              Adj Close   No. Observations:                 6164\n",
      "Model:                 ARIMA(5, 1, 0)   Log Likelihood              -10486.124\n",
      "Date:                Sat, 10 Aug 2024   AIC                          20984.249\n",
      "Time:                        14:48:02   BIC                          21024.607\n",
      "Sample:                             0   HQIC                         20998.245\n",
      "                               - 6164                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1         -0.0217      0.009     -2.438      0.015      -0.039      -0.004\n",
      "ar.L2         -0.0005      0.009     -0.057      0.954      -0.017       0.016\n",
      "ar.L3          0.0004      0.009      0.047      0.962      -0.017       0.017\n",
      "ar.L4        5.11e-07      0.009      6e-05      1.000      -0.017       0.017\n",
      "ar.L5          0.0069      0.009      0.742      0.458      -0.011       0.025\n",
      "sigma2         1.7595      0.012    152.641      0.000       1.737       1.782\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):             51430.67\n",
      "Prob(Q):                              1.00   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               3.17   Skew:                            -0.51\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                        17.11\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit model\n",
    "model = ARIMA(data, order=(5,1,0))\n",
    "model_fit = model.fit()\n",
    "# summary of fit model\n",
    "print(model_fit.summary())\n",
    "# line plot of residuals\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25f48c41-3498-40c2-ab81-e6a592e238e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0\n",
      "count  6164.000000\n",
      "mean      0.028799\n",
      "std       1.529874\n",
      "min     -14.988611\n",
      "25%      -0.569174\n",
      "50%       0.032143\n",
      "75%       0.627490\n",
      "max      59.880375\n"
     ]
    }
   ],
   "source": [
    "# density plot of residuals\n",
    "residuals.plot(kind='kde')\n",
    "plt.show()\n",
    "# summary stats of residuals\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037c8f14-6e1f-423f-a00d-de5826cb456f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
